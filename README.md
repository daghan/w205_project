# README

## Requirements:
To fully run this project, you need

- HDFS
- hive
- spark (and pyspark)
- jupyter
- tableau

## To get started  
1- Go to loading_and_modeling directory and run: ./load_data_lake.sh  

2- Then go to ../cleanup_and_transformations and run: ./clean_and_transform.sh

3- Then go to ../investigations and run: ./investigate.sh

4- Finally you can inspect the results (png file) at visualizations directory or
connect to the public tableau server at:  
https://public.tableau.com/profile/daghan.altas#!/vizhome/shared/ZZ57K43FD
